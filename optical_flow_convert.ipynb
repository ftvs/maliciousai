{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.io.video import read_video\n",
    "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights, raft_small, Raft_Small_Weights\n",
    "from torchvision.transforms.functional import resize\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import flow_to_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.cuda.amp import autocast\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import av"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\Datasets\\Celeb_DF\\YouTube-real\\00000.mp4\n",
      "torch.Size([450, 3, 500, 892])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path('H:/Datasets/Celeb_DF/YouTube-real')\n",
    "video_path = \"00000.mp4\"\n",
    "data_path = dataset_path / video_path\n",
    "# data_path = \"H:\\Datasets\\Celeb_DF\\YouTube-real\\00273.mp4\"\n",
    "\n",
    "print(data_path)\n",
    "# Load the video using torchvision\n",
    "vid, _, _ = read_video(data_path, output_format=\"TCHW\", pts_unit='sec')  # TCHW: Time, Channels, Height, Width\n",
    "# vid = vid[:32]  # Optionally, shorten the duration if needed (e.g., first 32 frames)\n",
    "print(vid.shape)\n",
    "\n",
    "# Display the optical flow image using OpenCV\n",
    "for frame in vid:\n",
    "    fr = cv2.cvtColor(frame.numpy().transpose(1, 2, 0), cv2.COLOR_BGR2RGB)\n",
    "    # print(fr.shape) # 500,892,3\n",
    "    cv2.imshow('input', fr)\n",
    "    # Wait for 25ms before moving to the next frame\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break  # Exit the loop if 'q' is pressed\n",
    "\n",
    "# Release the video window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAFT(\n",
       "  (feature_encoder): FeatureEncoder(\n",
       "    (convnormrelu): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (context_encoder): FeatureEncoder(\n",
       "    (convnormrelu): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): Identity()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (corr_block): CorrBlock()\n",
       "  (update_block): UpdateBlock(\n",
       "    (motion_encoder): MotionEncoder(\n",
       "      (convcorr1): Conv2dNormActivation(\n",
       "        (0): Conv2d(324, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convcorr2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convflow1): Conv2dNormActivation(\n",
       "        (0): Conv2d(2, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convflow2): Conv2dNormActivation(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (recurrent_block): RecurrentBlock(\n",
       "      (convgru1): ConvGRU(\n",
       "        (convz): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "        (convr): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "        (convq): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "      )\n",
       "      (convgru2): ConvGRU(\n",
       "        (convz): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        (convr): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "        (convq): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "      )\n",
       "    )\n",
       "    (flow_head): FlowHead(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (mask_predictor): MaskPredictor(\n",
       "    (convrelu): Conv2dNormActivation(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv): Conv2d(256, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the RAFT model with pre-trained weights\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = raft_large(weights=Raft_Large_Weights.DEFAULT).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAFT(\n",
       "  (feature_encoder): FeatureEncoder(\n",
       "    (convnormrelu): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (context_encoder): FeatureEncoder(\n",
       "    (convnormrelu): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(96, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (corr_block): CorrBlock()\n",
       "  (update_block): UpdateBlock(\n",
       "    (motion_encoder): MotionEncoder(\n",
       "      (convcorr1): Conv2dNormActivation(\n",
       "        (0): Conv2d(196, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convcorr2): Identity()\n",
       "      (convflow1): Conv2dNormActivation(\n",
       "        (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convflow2): Conv2dNormActivation(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): Conv2dNormActivation(\n",
       "        (0): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (recurrent_block): RecurrentBlock(\n",
       "      (convgru1): ConvGRU(\n",
       "        (convz): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (convr): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (convq): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (flow_head): FlowHead(\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load the RAFT model with pre-trained weights\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = raft_small(weights=Raft_Small_Weights.DEFAULT).to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing function (based on RAFT's input expectations)\n",
    "# def preprocess_frame(frame, device):\n",
    "#     frame_tensor = frame.float() / 255.0  # Normalize to [0, 1]\n",
    "#     frame_resized = resize(frame_tensor, size=[496, 888])  # Resize to match RAFT expectations 500, 892 ->  496, 888\n",
    "#     return frame_resized.unsqueeze(0).to(device)  # Add batch dimension and move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = Path('H:/Datasets/Celeb_DF/YouTube-real')\n",
    "# video_path = \"00000.mp4\"\n",
    "# data_path = dataset_path / video_path\n",
    "# # data_path = \"H:\\Datasets\\Celeb_DF\\YouTube-real\\00273.mp4\"\n",
    "\n",
    "# # Load the video using torchvision\n",
    "# vid, _, _ = read_video(data_path, output_format=\"TCHW\", pts_unit='sec')  # TCHW: Time, Channels, Height, Width\n",
    "\n",
    "# # Initialize video writer (if needed to save output)\n",
    "# fps = 30  # Change this according to the input video FPS\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "# out = cv2.VideoWriter('output_flow.avi', fourcc, fps, (888, 496))\n",
    "\n",
    "# # Process the video frame by frame\n",
    "# for i in range(vid.shape[0] - 1):\n",
    "#     prev_frame = vid[i]\n",
    "#     curr_frame = vid[i + 1]\n",
    "\n",
    "#     # Preprocess both frames\n",
    "#     prev_frame_tensor = preprocess_frame(prev_frame, device)\n",
    "#     curr_frame_tensor = preprocess_frame(curr_frame, device)\n",
    "#     # print(prev_frame_tensor.shape) #[1, 3, 496, 888]\n",
    "\n",
    "#     # Predict optical flow between the previous and current frames\n",
    "#     with torch.no_grad():\n",
    "#         flow_list = model(prev_frame_tensor, curr_frame_tensor)\n",
    "\n",
    "#         # flow_np = []\n",
    "#         # for flow in flow_list:\n",
    "#         #     flow_np.append(flow.cpu().numpy()) # Move tensor to CPU before converting to NumPy\n",
    "\n",
    "#         # print(np.array(flow_np).shape)  # (12, 1, 2, 496, 888)\n",
    "\n",
    "#         predicted_flow = flow_list[-1]  # Use the final output of the model\n",
    "#         # print(np.array(predicted_flow.cpu()).shape) # (1, 2, 496, 888)\n",
    "\n",
    "#     # Convert optical flow to an RGB image for visualizat ion\n",
    "#     flow_image = flow_to_image(predicted_flow.squeeze(0)).cpu().numpy().transpose(1, 2, 0) #(496, 888, 3)\n",
    "#     flow_image_bgr = cv2.cvtColor(flow_image.astype(np.uint8), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
    "\n",
    "#     # cv2.imshow('input', flow_image_bgr)\n",
    "#     # # Wait for 25ms before moving to the next frame\n",
    "#     # if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "#     #     break  # Exit the loop if 'q' is pressed\n",
    "\n",
    "#     # Save the flow image as part of the output video\n",
    "#     out.write(flow_image_bgr)\n",
    "\n",
    "# # Release the video writer\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the video using torchvision\n",
    "# # dataset_path = Path('H:/Datasets/Celeb_DF/YouTube-real')\n",
    "# # video_path = \"00000.mp4\"\n",
    "\n",
    "# dataset_path = Path('H:/Datasets/Celeb_DF/Celeb-synthesis')\n",
    "# video_path = \"id0_id1_0000.mp4\"\n",
    "\n",
    "# data_path = dataset_path / video_path\n",
    "# vid, _, _ = read_video(data_path, output_format=\"TCHW\", pts_unit='sec')  # TCHW: Time, Channels, Height, Width\n",
    "\n",
    "# # Initialize video writer (if needed to save output)\n",
    "# fps = 30  # Change this according to the input video FPS\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG') #h264 MJPG avc1 mpv4\n",
    "# out = cv2.VideoWriter('output_flow2.avi', fourcc, fps, (888, 496))\n",
    "\n",
    "# # Parameters\n",
    "# batch_size = 6  # Number of frames to process in a batch\n",
    "# num_frames = vid.shape[0]\n",
    "\n",
    "# # Process the video frame by frame in batches\n",
    "# for i in range(0, num_frames - 1, batch_size):\n",
    "#     # Prepare batch of frames\n",
    "#     batch_prev_frames = []\n",
    "#     batch_curr_frames = []\n",
    "    \n",
    "#     for j in range(batch_size):\n",
    "#         if i + j < num_frames - 1:\n",
    "#             batch_prev_frames.append(vid[i + j])\n",
    "#             batch_curr_frames.append(vid[i + j + 1])\n",
    "\n",
    "#     # Preprocess batches\n",
    "#     batch_prev_tensor = torch.cat([preprocess_frame(f, device) for f in batch_prev_frames], dim=0)\n",
    "#     batch_curr_tensor = torch.cat([preprocess_frame(f, device) for f in batch_curr_frames], dim=0)\n",
    "\n",
    "#     # Predict optical flow between the previous and current frames\n",
    "#     with torch.no_grad():\n",
    "#         # print(batch_prev_tensor.shape)\n",
    "#         flow_list = model(batch_prev_tensor, batch_curr_tensor)\n",
    "\n",
    "#         predicted_flows = flow_list[-1]  # Use the final output of the model\n",
    "\n",
    "#     # Convert optical flows to RGB images for visualization\n",
    "#     for flow in predicted_flows:\n",
    "#         flow_image = flow_to_image(flow.squeeze(0)).cpu().numpy().transpose(1, 2, 0)  # (496, 888, 3)\n",
    "#         flow_image_bgr = cv2.cvtColor(flow_image.astype(np.uint8), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
    "\n",
    "#         # Save the flow image as part of the output video\n",
    "#         out.write(flow_image_bgr)\n",
    "\n",
    "# # Release the video writer\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom Dataset class for video frames\n",
    "# class VideoFrameDataset(Dataset):\n",
    "#     def __init__(self, video_path):\n",
    "#         self.video_path = video_path\n",
    "#         self.vid, _, _ = read_video(video_path, output_format=\"TCHW\", pts_unit='sec')\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return self.vid.shape[0] - 1  # Last frame has no next frame\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         prev_frame = self.vid[idx]\n",
    "#         curr_frame = self.vid[idx + 1]\n",
    "#         return prev_frame, curr_frame\n",
    "    \n",
    "# # Preprocessing function (based on RAFT's input expectations)\n",
    "# def preprocess_frame(frame):\n",
    "#     frame_tensor = frame.float() / 255.0  # Normalize to [0, 1]\n",
    "#     frame_resized = resize(frame_tensor, size=[496, 888])  # Resize to match RAFT expectations 500, 892 ->  496, 888\n",
    "#     return frame_resized.unsqueeze(0)  # Add batch dimension and move to device\n",
    "\n",
    "# dataset_path = Path('H:/Datasets/Celeb_DF/YouTube-real')\n",
    "# video_path = \"00000.mp4\"\n",
    "\n",
    "# data_path = dataset_path / video_path\n",
    "\n",
    "# dataset = VideoFrameDataset(data_path)\n",
    "# data_loader = DataLoader(dataset, batch_size=6, shuffle=False, num_workers=0,pin_memory=True)\n",
    "\n",
    "# # Initialize video writer (if needed to save output)\n",
    "# fps = 30  # Change this according to the input video FPS\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'MJPG') #h264 MJPG avc1 mpv4\n",
    "# out = cv2.VideoWriter('output_flow2.avi', fourcc, fps, (888, 496))\n",
    "\n",
    "# # Process the video frames using DataLoader\n",
    "# for prev_frames, curr_frames in data_loader:\n",
    "#     # print(prev_frames.shape)\n",
    "#     # Preprocess batches\n",
    "#     batch_prev_tensor = torch.stack([preprocess_frame(f, device).to(device) for f in prev_frames]).to(device).squeeze(1)\n",
    "#     batch_curr_tensor = torch.stack([preprocess_frame(f, device).to(device) for f in curr_frames]).to(device).squeeze(1)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         # print(batch_prev_tensor.shape)\n",
    "#         flow_list = model(batch_prev_tensor, batch_curr_tensor)\n",
    "#         predicted_flows = flow_list[-1]  # Use the final output of the model\n",
    "\n",
    "#     # Convert optical flows to RGB images for visualization\n",
    "#     for flow in predicted_flows:\n",
    "#         flow_image = flow_to_image(flow.squeeze(0)).cpu().numpy().transpose(1, 2, 0)  # (496, 888, 3)\n",
    "#         flow_image_bgr = cv2.cvtColor(flow_image.astype(np.uint8), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
    "#         out.write(flow_image_bgr)\n",
    "\n",
    "# # Release the video writer\n",
    "# out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video compressed successfully to: output_flow_compressed3.mp4\n"
     ]
    }
   ],
   "source": [
    "# def compress_video(input_file, output_file, target_bitrate=500000):\n",
    "#     # Open the input file\n",
    "#     input_container = av.open(input_file)\n",
    "    \n",
    "#     # Create an output container to write the compressed video\n",
    "#     output_container = av.open(output_file, mode='w')\n",
    "\n",
    "#     # Set codec for the output video stream (e.g., H.264)\n",
    "#     output_stream = output_container.add_stream('h264', rate=30)  # 30 fps\n",
    "\n",
    "#     # Set the bitrate for compression\n",
    "#     output_stream.bit_rate = target_bitrate  # Bitrate in bits per second\n",
    "\n",
    "#     for frame in input_container.decode(video=0):\n",
    "#         # Re-encode the frames to the output video stream\n",
    "#         packet = output_stream.encode(frame)\n",
    "#         if packet:\n",
    "#             output_container.mux(packet)\n",
    "\n",
    "#     # Flush any remaining packets\n",
    "#     output_container.mux(output_stream.encode())\n",
    "    \n",
    "#     # Close the containers\n",
    "#     input_container.close()\n",
    "#     output_container.close()\n",
    "\n",
    "#     print(f\"Video compressed successfully to: {output_file}\")\n",
    "\n",
    "# # Example usage\n",
    "# input_video = 'output_flow.avi'\n",
    "# output_video = 'output_flow_compressed.mp4'\n",
    "\n",
    "# compress_video(input_video, output_video, target_bitrate=1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\Datasets\\Test\\00000.mp4\n",
      "output_flow_videos\\00000_flow.mp4\n",
      "Video compressed successfully to: output_flow_videos\\00000_flow.mp4\n",
      "output_flow_videos\\00001_flow.mp4\n",
      "Video compressed successfully to: output_flow_videos\\00001_flow.mp4\n"
     ]
    }
   ],
   "source": [
    "# # Custom Dataset class for multiple videos\n",
    "# class MultiVideoFrameDataset(Dataset):\n",
    "#     def __init__(self, video_dir):\n",
    "#         self.video_paths = list(video_dir.glob(\"*.mp4\"))  # Assume all videos are .mp4 files\n",
    "#         self.video_frames = []\n",
    "#         self.frame_indices = []\n",
    "\n",
    "#         # Preload all video frames and keep track of frame indices for all videos\n",
    "#         for video_path in self.video_paths:\n",
    "#             try:\n",
    "#                 vid, _, _ = read_video(video_path, output_format=\"TCHW\", pts_unit='sec')\n",
    "#                 for i in range(len(vid) - 1):  # Loop over frames in each video\n",
    "#                     self.video_frames.append((video_path, vid[i], vid[i + 1]))  # (video, frame_i, frame_i+1)\n",
    "#                     self.frame_indices.append(i)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error reading video file: {video_path}\")\n",
    "#                 print(e)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.video_frames)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         video_path, prev_frame, curr_frame = self.video_frames[idx]\n",
    "#         return video_path, prev_frame, curr_frame\n",
    "\n",
    "# # Custom collate_fn to handle video paths and frames separately\n",
    "# def custom_collate(batch):\n",
    "#     video_paths, prev_frames, curr_frames = zip(*batch)  # Unzip the batch into paths, previous frames, and current frames\n",
    "#     return list(video_paths), torch.stack(prev_frames), torch.stack(curr_frames)\n",
    "\n",
    "# # Preprocessing function (based on RAFT's input expectations)\n",
    "# def preprocess_frame(frame):\n",
    "#     frame_tensor = frame.float() / 255.0  # Normalize to [0, 1]\n",
    "#     frame_resized = resize(frame_tensor, size=[496, 888])  # Resize to match RAFT expectations 500, 892 ->  496, 888\n",
    "#     return frame_resized # Change to [C, H, W]  # Add batch dimension and move to device\n",
    "\n",
    "# def compress_video(input_file, output_file, target_bitrate=500000):\n",
    "#     # Open the input file\n",
    "#     input_container = av.open(input_file)\n",
    "    \n",
    "#     # Create an output container to write the compressed video\n",
    "#     output_container = av.open(output_file, mode='w')\n",
    "\n",
    "#     # Set codec for the output video stream (e.g., H.264)\n",
    "#     output_stream = output_container.add_stream('h264', rate=30)  # 30 fps\n",
    "\n",
    "#     # Set the bitrate for compression\n",
    "#     output_stream.bit_rate = target_bitrate  # Bitrate in bits per second\n",
    "\n",
    "#     for frame in input_container.decode(video=0):\n",
    "#         # Re-encode the frames to the output video stream\n",
    "#         packet = output_stream.encode(frame)\n",
    "#         if packet:\n",
    "#             output_container.mux(packet)\n",
    "\n",
    "#     # Flush any remaining packets\n",
    "#     output_container.mux(output_stream.encode())\n",
    "    \n",
    "#     # Close the containers\n",
    "#     input_container.close()\n",
    "#     output_container.close()\n",
    "\n",
    "#     print(f\"Video compressed successfully to: {output_file}\")\n",
    "\n",
    "# # Main function to process videos\n",
    "# def process_videos(video_dir, batch_size=6, num_workers=0, output_dir=\"output_videos\"):\n",
    "#     dataset = MultiVideoFrameDataset(video_dir)\n",
    "#     data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,collate_fn=custom_collate)\n",
    "\n",
    "#     # Ensure output directory exists\n",
    "#     Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Dictionary to store video writers for different videos\n",
    "#     video_writers = {}\n",
    "#     cur_vid = 'start'\n",
    "\n",
    "#     for video_path, prev_frames, curr_frames in data_loader:\n",
    "#         # Preprocess batches\n",
    "#         batch_prev_tensor = torch.stack([preprocess_frame(f).to(device) for f in prev_frames]).to(device)\n",
    "#         batch_curr_tensor = torch.stack([preprocess_frame(f).to(device) for f in curr_frames]).to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             # print(batch_prev_tensor.shape)\n",
    "#             # print(batch_curr_tensor.shape)\n",
    "#             flow_list = model(batch_prev_tensor, batch_curr_tensor)\n",
    "#             predicted_flows = flow_list[-1]  # Use the final output of the model\n",
    "\n",
    "#         # Loop through each batch and write output to corresponding video\n",
    "#         for idx, flow in enumerate(predicted_flows):\n",
    "#             # Get the video path and ensure the video writer is initialized\n",
    "#             video_file = video_path[idx]\n",
    "#             # print(video_file)\n",
    "#             if cur_vid == 'start':\n",
    "#                 cur_vid = video_file\n",
    "#                 # print(cur_vid)\n",
    "\n",
    "#             if video_file != cur_vid:\n",
    "#                 output_video_path = Path(output_dir) / f\"{cur_vid.stem}_flow.mp4\"\n",
    "#                 print(output_video_path)\n",
    "#                 compress_video(temp_path, output_video_path, target_bitrate=1500000)\n",
    "#                 cur_vid = video_file\n",
    "\n",
    "#             if video_file not in video_writers:\n",
    "#                 temp_path = \"temp.avi\"\n",
    "#                 fps = 30  # Change according to input video FPS\n",
    "#                 fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "#                 video_writers[video_file] = cv2.VideoWriter(temp_path, fourcc, fps, (888, 496))\n",
    "\n",
    "#             # Convert flow to image and write to video\n",
    "#             flow_image = flow_to_image(flow.squeeze(0)).cpu().numpy().transpose(1, 2, 0)  # (496, 888, 3)\n",
    "#             flow_image_bgr = cv2.cvtColor(flow_image.astype(np.uint8), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
    "#             video_writers[video_file].write(flow_image_bgr)\n",
    "\n",
    "\n",
    "#     # Release all video writers\n",
    "#     for writer in video_writers.values():\n",
    "#         writer.release()\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Path to directory containing videos\n",
    "# # video_dir = Path('H:/Datasets/Celeb_DF/YouTube-real')\n",
    "# video_dir = Path('H:/Datasets/Test')\n",
    "# # Output directory to save flow videos\n",
    "# output_dir = \"output_flow_videos\"\n",
    "\n",
    "# # Process videos\n",
    "# process_videos(video_dir, batch_size=6, num_workers=0, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for video frames\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self, video_path, transform):\n",
    "        self.video_path = video_path\n",
    "        self.vid, _, _ = read_video(video_path, output_format=\"TCHW\", pts_unit='sec')\n",
    "\n",
    "        # Clip frames to the fixed number `max_frames`\n",
    "        self.max_frames = 300\n",
    "        self.vid = self._clip_frames(self.vid)\n",
    "\n",
    "        # sample n number of frames from clipped video\n",
    "        self.n_frames = 150\n",
    "        self.vid = self._sample_frames(self.vid)\n",
    "\n",
    "        self.vid = transform(self.vid)\n",
    "        # print(self.vid.shape)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.vid.shape[0] - 1  # Last frame has no next frame\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prev_frame = self.vid[idx]\n",
    "        curr_frame = self.vid[idx + 1]\n",
    "        return prev_frame, curr_frame\n",
    "    \n",
    "    def _clip_frames(self, frames):\n",
    "        \"\"\"Clip the video frames to a fixed number of frames `max_frames`.\"\"\"\n",
    "        # If the video has more frames than max_frames, clip it to the first `max_frames`\n",
    "        if len(frames) > self.max_frames:\n",
    "            return frames[:self.max_frames]\n",
    "        \n",
    "        # If the video has fewer frames than `max_frames`, pad with zeros\n",
    "        pad_size = self.max_frames - len(frames)\n",
    "        pad_frames = torch.zeros((pad_size, *frames.shape[1:]))  # Create padding frames with same size\n",
    "        frames = torch.cat([frames, pad_frames], dim=0)\n",
    "        \n",
    "        return frames\n",
    "    \n",
    "    def _sample_frames(self, frames):\n",
    "        \"\"\"Sample n number of frames from cliped video\"\"\"\n",
    "        if len(frames) > self.n_frames:\n",
    "            indices = torch.linspace(0, len(frames)-1, steps=self.n_frames).long()\n",
    "            frames = frames[indices]  \n",
    "        \n",
    "        return frames\n",
    "\n",
    "\n",
    "# Preprocessing function (based on RAFT's input expectations)\n",
    "# def preprocess_frame(frame):\n",
    "#     frame_tensor = frame.float() / 255.0  # Normalize to [0, 1]\n",
    "#     frame_resized = resize(frame_tensor, size=[496, 888])  # Resize to match RAFT expectations 500, 892 ->  496, 888\n",
    "#     return frame_resized.unsqueeze(0)  # Add batch dimension and move to device\n",
    "\n",
    "preprocess = T.Compose([\n",
    "    T.ConvertImageDtype(torch.float32),\n",
    "    T.Normalize(mean=(0.43216, 0.394666, 0.37645),\n",
    "                std=(0.22803, 0.22145, 0.216989)),\n",
    "    T.Resize([256, 256]),\n",
    "])\n",
    "\n",
    "# def preprocess_frame(frame):\n",
    "#     return preprocess(frame).unsqueeze(0)  # Preprocess and add batch dimension\n",
    "\n",
    "def process_single_video(video_path, model):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load the dataset\n",
    "    dataset = VideoFrameDataset(video_path,preprocess)\n",
    "    data_loader = DataLoader(dataset, batch_size=75, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # Initialize video writer\n",
    "    fps = 15  # Adjust if needed\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    # output_file = output_dir / (video_path.stem + '_flow.avi')\n",
    "    output_file = \"temp.avi\"\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (256, 256))\n",
    "\n",
    "    # Process video frames\n",
    "    for prev_frames, curr_frames in data_loader:\n",
    "        # Preprocess batches\n",
    "        batch_prev_tensor = torch.stack([f.unsqueeze(0).to(device) for f in prev_frames]).squeeze(1)\n",
    "        batch_curr_tensor = torch.stack([f.unsqueeze(0).to(device) for f in curr_frames]).squeeze(1)\n",
    "        # print(batch_prev_tensor.shape)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                # Predict optical flows\n",
    "                flow_list = model(batch_prev_tensor, batch_curr_tensor)\n",
    "                predicted_flows = flow_list[-1]  # Final output\n",
    "\n",
    "        # Convert optical flows to RGB and write to video\n",
    "        for flow in predicted_flows:\n",
    "            flow_image = flow_to_image(flow.squeeze(0)).cpu().numpy().transpose(1, 2, 0)  # (496, 888, 3)\n",
    "            flow_image_bgr = cv2.cvtColor(flow_image.astype(np.uint8), cv2.COLOR_RGB2BGR)  # Convert to BGR for OpenCV\n",
    "            out.write(flow_image_bgr)\n",
    "\n",
    "        # # Clear tensors and free memory\n",
    "        # del batch_prev_tensor, batch_curr_tensor, flow_list, predicted_flows\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "    # Release resources\n",
    "    out.release()\n",
    "\n",
    "def compress_video(input_file, output_file, target_bitrate=500000):\n",
    "    # Open the input file\n",
    "    input_container = av.open(input_file)\n",
    "    \n",
    "    # Create an output container to write the compressed video\n",
    "    output_container = av.open(output_file, mode='w')\n",
    "\n",
    "    # Set codec for the output video stream (e.g., H.264)\n",
    "    output_stream = output_container.add_stream('h264', rate=15)  # 30 fps\n",
    "\n",
    "    # Set the bitrate for compression\n",
    "    output_stream.bit_rate = target_bitrate  # Bitrate in bits per second\n",
    "\n",
    "    # Set the resolution of the output video stream based on the input stream\n",
    "    output_stream.width = 256\n",
    "    output_stream.height = 256\n",
    "\n",
    "    for frame in input_container.decode(video=0):\n",
    "        # Re-encode the frames to the output video stream\n",
    "        packet = output_stream.encode(frame)\n",
    "        if packet:\n",
    "            output_container.mux(packet)\n",
    "\n",
    "    # Flush any remaining packets\n",
    "    output_container.mux(output_stream.encode())\n",
    "    \n",
    "    # Close the containers\n",
    "    input_container.close()\n",
    "    output_container.close()\n",
    "\n",
    "    # print(f\"Video compressed successfully to: {output_file}\")\n",
    "\n",
    "def process_videos_in_folder(folder_path, model, output_dir):\n",
    "    video_paths = sorted(Path(folder_path).glob('*.mp4'))  # Assumes .mp4, adjust if necessary\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for video_path in video_paths:\n",
    "        # print(f\"Processing video: {video_path}\")\n",
    "        process_single_video(video_path, model)\n",
    "\n",
    "        # Optionally compress the video after processing\n",
    "        input_vid = \"temp.avi\"\n",
    "        compressed_output_file = output_dir / (video_path.stem + '.mp4')\n",
    "        compress_video(input_vid, compressed_output_file, target_bitrate=1500000)\n",
    "\n",
    "\n",
    "# folder_path = Path('H:/Datasets/maliciousai/data/Celeb-DF-v2/YouTube-real')\n",
    "# output_dir = Path('H:/Datasets/maliciousai/data/Celeb-DF-v2-Flow/YouTube-real')\n",
    "\n",
    "# folder_path = Path('H:/Datasets/maliciousai/data/Celeb-DF-v2/Celeb-real')\n",
    "# output_dir = Path('H:/Datasets/maliciousai/data/Celeb-DF-v2-Flow/Celeb-real')\n",
    "\n",
    "folder_path = Path('H:/Datasets/maliciousai/data/Celeb-synthesis')\n",
    "output_dir = Path('H:/Datasets/maliciousai/data/Celeb-DF-v2-Flow/Celeb-synthesis')\n",
    "\n",
    "process_videos_in_folder(folder_path, model, output_dir) # 3.8s per video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Learning_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
